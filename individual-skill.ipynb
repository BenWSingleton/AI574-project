{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a902e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError\n",
    "import atexit\n",
    "import requests\n",
    "\n",
    "BASE = Path(\".\")\n",
    "RESUME_PARQUET = BASE / \"processed\" / \"resume_matched.parquet\"\n",
    "JOB_PARQUET    = BASE / \"processed\" / \"dice_job_descriptions_matched.parquet\"\n",
    "MATCH_DIR      = BASE / \"matches\"\n",
    "CACHE_FILE     = MATCH_DIR / \"skill_cache.json\"\n",
    "\n",
    "MATCH_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "EMBED_MODEL = \"nomic-embed-text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d34827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 120 resumes and 22,000 jobs\n",
      "Resume columns: ['ID', 'Resume_str', 'Resume_html', 'Category', 'extracted_skills', 'length', 'matched_skills']\n",
      "Job columns:    ['advertiserurl', 'company', 'employmenttype_jobstatus', 'jobdescription', 'jobid', 'joblocation_address', 'jobtitle', 'postdate', 'shift', 'site_name', 'skills', 'uniq_id', 'extracted_skills', 'matched_skills']\n"
     ]
    }
   ],
   "source": [
    "resumes = pd.read_parquet(RESUME_PARQUET)\n",
    "jobs    = pd.read_parquet(JOB_PARQUET)\n",
    "\n",
    "resumes = resumes[resumes['Category'] == 'INFORMATION-TECHNOLOGY']\n",
    "\n",
    "print(f\"Loaded {len(resumes):,} resumes and {len(jobs):,} jobs\")\n",
    "print(\"Resume columns:\", resumes.columns.tolist())\n",
    "print(\"Job columns:   \", jobs.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd16267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_esco_skills(row):\n",
    "    \"\"\"\n",
    "    Extract ESCO labels from 'matched_skills' column.\n",
    "    Works with: list, np.ndarray, tuple, str, None, NaN.\n",
    "    \"\"\"\n",
    "    if hasattr(row, '_fields'):\n",
    "        raw = getattr(row, 'matched_skills', None)\n",
    "    else:\n",
    "        raw = row.get('matched_skills', None)\n",
    "\n",
    "    if raw is None:\n",
    "        return []\n",
    "\n",
    "    if isinstance(raw, float) and pd.isna(raw):\n",
    "        return []\n",
    "\n",
    "    if isinstance(raw, (list, np.ndarray, tuple)):\n",
    "        return [str(s).strip() for s in raw if str(s).strip()]\n",
    "\n",
    "    if isinstance(raw, str):\n",
    "        import ast\n",
    "        try:\n",
    "            parsed = ast.literal_eval(raw)\n",
    "            if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                return [str(s).strip() for s in parsed if str(s).strip()]\n",
    "        except:\n",
    "            pass\n",
    "        return [s.strip() for s in raw.split(',') if s.strip()]\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c0a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache with 3743 skills...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.save_cache()>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_cache = {}\n",
    "if CACHE_FILE.exists():\n",
    "    print(f\"Loading cache with {len(json.load(open(CACHE_FILE)))} skills...\")\n",
    "    skill_cache = {k: np.array(v) for k, v in json.load(open(CACHE_FILE)).items()}\n",
    "\n",
    "def embed_skill(skill, timeout=30):\n",
    "    skill = skill.strip()\n",
    "    if skill in skill_cache:\n",
    "        return skill_cache[skill]\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/embeddings\",\n",
    "            json={\"model\": EMBED_MODEL, \"prompt\": skill},\n",
    "            timeout=timeout\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        vec = np.array(response.json()[\"embedding\"])\n",
    "        skill_cache[skill] = vec\n",
    "        return vec\n",
    "    except requests.Timeout:\n",
    "        print(f\"[TIMEOUT] Embedding '{skill}' took >{timeout}s\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Embedding '{skill}' failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def embed_list(skills):\n",
    "    vectors = []\n",
    "    for s in skills:\n",
    "        vec = embed_skill(s)\n",
    "        if vec is not None:\n",
    "            vectors.append(vec)\n",
    "    return np.vstack(vectors) if vectors else np.array([]).reshape(0, 768)\n",
    "\n",
    "def save_cache():\n",
    "    print(f\"Saving {len(skill_cache):,} skills to {CACHE_FILE}\")\n",
    "    json.dump({k: v.tolist() for k, v in skill_cache.items()}, open(CACHE_FILE, \"w\"))\n",
    "atexit.register(save_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72cfd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_resume_job(resume_row, job_row, thresh=0.85, top_k=3):\n",
    "    r_skills = list(set(get_esco_skills(resume_row)))\n",
    "    j_skills = list(set(get_esco_skills(job_row)))\n",
    "    if not r_skills or not j_skills:\n",
    "        return None\n",
    "\n",
    "    r_emb = embed_list(r_skills)\n",
    "    j_emb = embed_list(j_skills)\n",
    "    if r_emb.size == 0 or j_emb.size == 0:\n",
    "        return None\n",
    "\n",
    "    sim = cosine_similarity(r_emb, j_emb)\n",
    "\n",
    "    covered = (sim >= thresh).any(axis=0)\n",
    "    covered_job_skills = [js for js, cov in zip(j_skills, covered) if cov]\n",
    "    missing_job_skills = [js for js, cov in zip(j_skills, covered) if not cov]\n",
    "\n",
    "    top_matches = []\n",
    "    for j, js in enumerate(j_skills):\n",
    "        scores = sim[:, j]\n",
    "        best_idx = np.argsort(scores)[-top_k:][::-1]\n",
    "        for idx in best_idx:\n",
    "            if scores[idx] > 0:\n",
    "                top_matches.append({\n",
    "                    \"job_skill\": js,\n",
    "                    \"resume_skill\": r_skills[idx],\n",
    "                    \"score\": float(scores[idx]),\n",
    "                    \"is_match\": scores[idx] >= thresh\n",
    "                })\n",
    "\n",
    "    summary = {\n",
    "        \"resume_id\"         : resume_row.ID if hasattr(resume_row, 'ID') else resume_row.get('ID'),\n",
    "        \"job_id\"            : job_row.uniq_id if hasattr(job_row, 'uniq_id') else job_row.get('uniq_id'),\n",
    "        \"pct_job_covered\"   : float((len(covered_job_skills)/len(j_skills))),      \n",
    "        \"gaps\"              : missing_job_skills,\n",
    "        \"n_gaps\"            : len(missing_job_skills),\n",
    "        \"n_job_skills\"      : len(j_skills),\n",
    "        \"n_job_covered\"     : len(covered_job_skills),\n",
    "        \"top_matches\"       : top_matches\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"summary\"    : summary,\n",
    "        \"sim_matrix\" : sim,\n",
    "        \"r_skills\"   : r_skills,\n",
    "        \"j_skills\"   : j_skills\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae07656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unique ESCO skills from resumes and jobs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845f99d2778149709033dc1b51f92cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resumes:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4012a7c729456096550f772b8b7024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Jobs:   0%|          | 0/22000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2,604 unique ESCO skills\n",
      "Pre-embedding unique skills...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfba168f50044db187ea682fed7f0cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding:   0%|          | 0/2604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 new embeddings\n",
      "Saving full cache (3,743 skills) → matches\\skill_cache.json\n",
      "Pre-embedding complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting unique ESCO skills from resumes and jobs...\")\n",
    "unique_skills = set()\n",
    "\n",
    "# Resumes\n",
    "for row in tqdm(resumes.itertuples(), total=len(resumes), desc=\"Resumes\"):\n",
    "    unique_skills.update(get_esco_skills(row))\n",
    "\n",
    "# Jobs\n",
    "for row in tqdm(jobs.itertuples(), total=len(jobs), desc=\"Jobs\"):\n",
    "    unique_skills.update(get_esco_skills(row))\n",
    "\n",
    "unique_skills = sorted(unique_skills)\n",
    "print(f\"Found {len(unique_skills):,} unique ESCO skills\")\n",
    "\n",
    "print(\"Pre-embedding unique skills...\")\n",
    "new_embeddings = 0\n",
    "\n",
    "for skill in tqdm(unique_skills, desc=\"Embedding\"):\n",
    "    if skill not in skill_cache:\n",
    "        vec = embed_skill(skill)\n",
    "        if vec is not None:\n",
    "            skill_cache[skill] = vec\n",
    "            new_embeddings += 1\n",
    "        else:\n",
    "            print(f\"[SKIP] Failed to embed: {skill}\")\n",
    "\n",
    "print(f\"Added {new_embeddings:,} new embeddings\")\n",
    "\n",
    "print(f\"Saving full cache ({len(skill_cache):,} skills) → {CACHE_FILE}\")\n",
    "json.dump({k: v.tolist() for k, v in skill_cache.items()}, open(CACHE_FILE, \"w\"))\n",
    "print(\"Pre-embedding complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0354645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 120 tech resumes × 22,000 jobs = 2,640,000 total possible pairs\n",
      "\n",
      "Building valid pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7504eebf788444daa1b3d981851600b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning resumes:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID PAIRS FOUND     : 2,553,383\n",
      "TOTAL BATCHES TO RUN  : 2,554\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Starting matching of 2,553,383 pairs in 2554 batches\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2750841f254569bbba11816105de9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/2554 [  0%]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE! 2,553,383 matched pairs → matches\\ind_skills_scores_085.parquet\n"
     ]
    }
   ],
   "source": [
    "THRESH          = 0.85\n",
    "MAX_WORKERS     = 8\n",
    "BATCH_SIZE      = 1000\n",
    "PAIR_TIMEOUT    = 60\n",
    "SUMMARY_FILE    = MATCH_DIR / \"ind_skills_scores_085.parquet\"\n",
    "\n",
    "print(f\"Using {len(resumes):,} tech resumes × {len(jobs):,} jobs \"\n",
    "      f\"= {len(resumes)*len(jobs):,} total possible pairs\")\n",
    "\n",
    "print(\"\\nBuilding valid pairs...\")\n",
    "pairs = []\n",
    "for r in tqdm(resumes.itertuples(), total=len(resumes), desc=\"Scanning resumes\"):\n",
    "    r_skills = get_esco_skills(r)\n",
    "    if not r_skills:\n",
    "        continue\n",
    "    for j in jobs.itertuples():\n",
    "        j_skills = get_esco_skills(j)\n",
    "        if j_skills:\n",
    "            pairs.append((r, j))\n",
    "\n",
    "total_pairs = len(pairs)\n",
    "total_batches = (total_pairs + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "print(f\"\\nVALID PAIRS FOUND     : {total_pairs:,}\")\n",
    "print(f\"TOTAL BATCHES TO RUN  : {total_batches:,}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "def match_with_timeout(r, j):\n",
    "    with ThreadPoolExecutor(max_workers=1) as exe:\n",
    "        fut = exe.submit(match_resume_job, r, j, THRESH)\n",
    "        try:\n",
    "            return fut.result(timeout=PAIR_TIMEOUT)\n",
    "        except TimeoutError:\n",
    "            print(f\"[TIMEOUT] Resume {getattr(r, 'ID', '?')} ↔ Job {getattr(j, 'uniq_id', '?')}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Resume {getattr(r, 'ID', '?')} ↔ Job {getattr(j, 'uniq_id', '?')}: {e}\")\n",
    "            return None\n",
    "\n",
    "print(f\"\\nStarting matching of {total_pairs:,} pairs in {total_batches} batches\\n\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "with tqdm(total=total_batches, desc=\"Overall Progress\", unit=\"batch\", \n",
    "          bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{percentage:3.0f}%]\") as pbar:\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:\n",
    "        for batch_idx in range(1, total_batches + 1):\n",
    "            start = (batch_idx - 1) * BATCH_SIZE\n",
    "            end = start + BATCH_SIZE\n",
    "            batch = pairs[start:end]\n",
    "\n",
    "            futures = [exe.submit(match_with_timeout, r, j) for r, j in batch]\n",
    "\n",
    "            for fut in as_completed(futures):\n",
    "                result = fut.result()\n",
    "                if result:\n",
    "                    summary_rows.append(result[\"summary\"])\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "# ────────────────────── FINAL SAVE ──────────────────────\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_parquet(SUMMARY_FILE, index=False)\n",
    "\n",
    "print(f\"\\nDONE! {len(summary_df):,} matched pairs → {SUMMARY_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf74077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"matches/ind_skills_scores_085.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e71c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df['gaps'] = df['gaps'].apply(lambda x: literal_eval(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f5b7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes_all = pd.read_parquet(\"processed/resume_matched.parquet\")\n",
    "jobs_all    = pd.read_parquet(\"processed/dice_job_descriptions_matched.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3259e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df['pct_job_covered'] * df['n_job_skills'].apply(lambda x: np.log1p(x))\n",
    "\n",
    "best = df.loc[df.groupby('resume_id')['score'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ede99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Resume 16186411 → Job 87fbe5a19977daf7b44de1f025da7cb2\n",
      "Reported pct_job_covered = 0.818 (9/11)\n",
      "Predicted gaps (2): ['PHP' 'Ruby (computer programming)']\n",
      "==================================================================================================================================\n",
      "Resume ESCO skills found : 11\n",
      "Job ESCO skills found    : 11\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "['ASP.NET', 'SQL Server', 'PHP', 'Ruby (computer programming)', 'CSS', 'Java (computer programming)', 'MySQL', 'C#', 'LINQ', 'AJAX', 'JavaScript']\n",
      "['ASP.NET', 'C++', 'CSS', 'Java (computer programming)', 'SQL', 'MySQL', 'Microsoft Access', 'AJAX', 'C#', 'LINQ', 'JavaScript']\n",
      "9\n",
      "2\n",
      "TOP 10 STRONGEST SKILL PAIRS:\n",
      "  1.000  →  \"ASP.NET\"  ↔  \"ASP.NET\"  [MATCH]\n",
      "  1.000  →  \"C#\"  ↔  \"C#\"  [MATCH]\n",
      "  1.000  →  \"AJAX\"  ↔  \"AJAX\"  [MATCH]\n",
      "  1.000  →  \"MySQL\"  ↔  \"MySQL\"  [MATCH]\n",
      "  1.000  →  \"CSS\"  ↔  \"CSS\"  [MATCH]\n",
      "  1.000  →  \"Java (computer programming)\"  ↔  \"Java (computer programming)\"  [MATCH]\n",
      "  1.000  →  \"LINQ\"  ↔  \"LINQ\"  [MATCH]\n",
      "  1.000  →  \"JavaScript\"  ↔  \"JavaScript\"  [MATCH]\n",
      "  0.866  →  \"SQL\"  ↔  \"SQL Server\"  [MATCH]\n",
      "  0.743  →  \"Java (computer programming)\"  ↔  \"Ruby (computer programming)\"  [close]\n"
     ]
    }
   ],
   "source": [
    "row = best[best['resume_id'] == 16186411].iloc[0]\n",
    "\n",
    "rid = row['resume_id']\n",
    "jid = row['job_id']\n",
    "thresh = 0.85\n",
    "\n",
    "print(f\"Inspecting Resume {rid} → Job {jid}\")\n",
    "print(f\"Reported pct_job_covered = {row['pct_job_covered']:.3f} ({row['n_job_covered']}/{row['n_job_skills']})\")\n",
    "#print(f\"Job skills that matched with resume {row['matched_job_skills']}\")\n",
    "print(f\"Predicted gaps ({len(row['gaps'])}): {row['gaps']}\")\n",
    "print(\"=\"*130)\n",
    "\n",
    "resume_row = resumes_all[resumes_all['ID'] == rid].iloc[0]\n",
    "job_row    = jobs_all[jobs_all['uniq_id'] == jid].iloc[0]\n",
    "\n",
    "r_skills = list(set(get_esco_skills(resume_row)))\n",
    "j_skills = list(set(get_esco_skills(job_row)))\n",
    "\n",
    "print(f\"Resume ESCO skills found : {len(r_skills)}\")\n",
    "print(f\"Job ESCO skills found    : {len(j_skills)}\")\n",
    "print(\"-\"*130)\n",
    "print(j_skills)\n",
    "print(r_skills)\n",
    "\n",
    "# matches = pd.DataFrame(row['top_matches'])\n",
    "\n",
    "# print(\"Explainability for this match:\")\n",
    "# display(matches.sort_values('score', ascending=False))\n",
    "\n",
    "r_emb = embed_list(r_skills)\n",
    "j_emb = embed_list(j_skills)\n",
    "sim   = cosine_similarity(r_emb, j_emb)\n",
    "\n",
    "covered = (sim >= thresh).any(axis=0)\n",
    "covered_job_skills = [js for js, cov in zip(j_skills, covered) if cov]\n",
    "missing_job_skills = [js for js, cov in zip(j_skills, covered) if not cov]\n",
    "\n",
    "print(len(covered_job_skills))\n",
    "print(len(missing_job_skills))\n",
    "\n",
    "print(\"TOP 10 STRONGEST SKILL PAIRS:\")\n",
    "matches = []\n",
    "for i, rs in enumerate(r_skills):\n",
    "    for j, js in enumerate(j_skills):\n",
    "        matches.append((sim[i,j], rs, js))\n",
    "for score, rs, js in sorted(matches, reverse=True)[:10]:\n",
    "    status = \"MATCH\" if score >= thresh else \"close\"\n",
    "    print(f\"  {score:.3f}  →  \\\"{rs}\\\"  ↔  \\\"{js}\\\"  [{status}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "878f95c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Resume 17111768 → Job e7e326053c586bd94e59f1fd74de4a1b\n",
      "Reported pct_job_covered = 0.750 (3/4)\n",
      "Predicted gaps (1): ['coordinate security']\n",
      "==================================================================================================================================\n",
      "Resume ESCO skills found : 16\n",
      "Job ESCO skills found    : 4\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "['coordinate security', 'process applications', 'operating systems', 'project management']\n",
      "['perform system analysis', 'database management systems', 'computer technology', 'financial analysis', 'government policy implementation', 'process applications', 'project management', 'deliver business research proposals', 'organise project meetings', 'customer service', 'investigation research methods', 'perform political negotiation', 'policy analysis', 'create a financial report', 'operating systems', 'analyse network configuration and performance']\n",
      "3\n",
      "1\n",
      "TOP 10 STRONGEST SKILL PAIRS:\n",
      "  1.000  →  \"project management\"  ↔  \"project management\"  [MATCH]\n",
      "  1.000  →  \"process applications\"  ↔  \"process applications\"  [MATCH]\n",
      "  1.000  →  \"operating systems\"  ↔  \"operating systems\"  [MATCH]\n",
      "  0.685  →  \"organise project meetings\"  ↔  \"project management\"  [close]\n",
      "  0.583  →  \"database management systems\"  ↔  \"operating systems\"  [close]\n",
      "  0.579  →  \"perform system analysis\"  ↔  \"operating systems\"  [close]\n",
      "  0.575  →  \"computer technology\"  ↔  \"operating systems\"  [close]\n",
      "  0.533  →  \"database management systems\"  ↔  \"project management\"  [close]\n",
      "  0.514  →  \"perform system analysis\"  ↔  \"process applications\"  [close]\n",
      "  0.491  →  \"computer technology\"  ↔  \"process applications\"  [close]\n"
     ]
    }
   ],
   "source": [
    "row = best[best['pct_job_covered'] > 0.5].sample(1, random_state=45).iloc[0]\n",
    "\n",
    "rid = row['resume_id']\n",
    "jid = row['job_id']\n",
    "\n",
    "print(f\"Inspecting Resume {rid} → Job {jid}\")\n",
    "print(f\"Reported pct_job_covered = {row['pct_job_covered']:.3f} ({row['n_job_covered']}/{row['n_job_skills']})\")\n",
    "print(f\"Predicted gaps ({len(row['gaps'])}): {row['gaps']}\")\n",
    "print(\"=\"*130)\n",
    "\n",
    "resume_row = resumes_all[resumes_all['ID'] == rid].iloc[0]\n",
    "job_row    = jobs_all[jobs_all['uniq_id'] == jid].iloc[0]\n",
    "\n",
    "r_skills = list(set(get_esco_skills(resume_row)))\n",
    "j_skills = list(set(get_esco_skills(job_row)))\n",
    "\n",
    "print(f\"Resume ESCO skills found : {len(r_skills)}\")\n",
    "print(f\"Job ESCO skills found    : {len(j_skills)}\")\n",
    "print(\"-\"*130)\n",
    "print(j_skills)\n",
    "print(r_skills)\n",
    "\n",
    "r_emb = embed_list(r_skills)\n",
    "j_emb = embed_list(j_skills)\n",
    "sim   = cosine_similarity(r_emb, j_emb)\n",
    "\n",
    "covered = (sim >= thresh).any(axis=0)\n",
    "covered_job_skills = [js for js, cov in zip(j_skills, covered) if cov]\n",
    "missing_job_skills = [js for js, cov in zip(j_skills, covered) if not cov]\n",
    "\n",
    "print(len(covered_job_skills))\n",
    "print(len(missing_job_skills))\n",
    "\n",
    "print(\"TOP 10 STRONGEST SKILL PAIRS:\")\n",
    "matches = []\n",
    "for i, rs in enumerate(r_skills):\n",
    "    for j, js in enumerate(j_skills):\n",
    "        matches.append((sim[i,j], rs, js))\n",
    "for score, rs, js in sorted(matches, reverse=True)[:10]:\n",
    "    status = \"MATCH\" if score >= thresh else \"close\"\n",
    "    print(f\"  {score:.3f}  →  \\\"{rs}\\\"  ↔  \\\"{js}\\\"  [{status}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
