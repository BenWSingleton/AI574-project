{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81efe04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scoring\n",
    "from ast import literal_eval\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c6cff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.read_parquet('processed/resume_matched.parquet')\n",
    "jobs = pd.read_parquet('processed/dice_job_descriptions_matched.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18bdba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return [str(item).strip() for item in x if str(item).strip()]\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return [str(item).strip() for item in x.flatten() if str(item).strip()]\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            parsed = literal_eval(x)\n",
    "            if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                return [str(item).strip() for item in parsed if str(item).strip()]\n",
    "        except:\n",
    "            pass\n",
    "        return [s.strip() for s in x.replace('[','').replace(']','').split(',') if s.strip()]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd77fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.read_parquet('processed/resume_matched.parquet', columns=['ID', 'matched_skills'])\n",
    "jobs = pd.read_parquet('processed/dice_job_descriptions_matched.parquet', columns=['jobid', 'matched_skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77e607d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['matched_skills'] = resumes['matched_skills'].apply(parse)\n",
    "jobs['matched_skills'] = jobs['matched_skills'].apply(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40c390ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    \"0.45\": \"matches/ind_skills_scores_045.parquet\",\n",
    "    \"0.55\": \"matches/ind_skills_scores_055.parquet\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60295ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_tech = {\n",
    "    \"0.65\": \"matches/ind_skills_scores_065.parquet\",\n",
    "    \"0.75\": \"matches/ind_skills_scores_075.parquet\",\n",
    "    \"0.85\": \"matches/ind_skills_scores_085.parquet\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1de6f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating threshold 0.65...\n",
      "  → 119 resumes have a best match\n",
      "\n",
      "Evaluating threshold 0.75...\n",
      "  → 119 resumes have a best match\n",
      "\n",
      "Evaluating threshold 0.85...\n",
      "  → 119 resumes have a best match\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, path in thresholds_tech.items():\n",
    "    print(f\"\\nEvaluating threshold {name}...\")\n",
    "    \n",
    "    parquet_file = pq.ParquetFile(path)\n",
    "    best_pct = {}\n",
    "\n",
    "    for batch in parquet_file.iter_batches(batch_size=200_000, columns=['resume_id', 'job_id', 'pct_covered', 'gaps']):\n",
    "        df_chunk = batch.to_pandas()\n",
    "        df_chunk['gaps_parsed'] = df_chunk['gaps'].apply(parse)\n",
    "\n",
    "        for row in df_chunk.itertuples(index=False):\n",
    "            rid = row.resume_id\n",
    "            pct = row.pct_covered\n",
    "            row_dict = {\n",
    "                'resume_id'   : rid,\n",
    "                'job_id'      : row.job_id,\n",
    "                'pct_covered' : pct,\n",
    "                'gaps'        : row.gaps_parsed\n",
    "            }\n",
    "            if rid not in best_pct or pct > best_pct[rid][0]:\n",
    "                best_pct[rid] = (pct, row_dict)\n",
    "\n",
    "    best_list = [data for _, data in best_pct.values()]\n",
    "    best_df = pd.DataFrame(best_list)\n",
    "    print(f\"  → {len(best_df):,} resumes have a best match\")\n",
    "\n",
    "    best_df = best_df.merge(resumes.rename(columns={'ID':'resume_id','matched_skills':'resume_matched'}), \n",
    "                            on='resume_id', how='left')\n",
    "    best_df = best_df.merge(jobs.rename(columns={'jobid':'job_id','matched_skills':'job_matched'}), \n",
    "                            on='job_id', how='left')\n",
    "\n",
    "    best_df['resume_matched'] = best_df['resume_matched'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    best_df['job_matched'] = best_df['job_matched'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "    true_missing = [list(set(row.job_matched) - set(row.resume_matched)) \n",
    "                    for row in best_df.itertuples()]\n",
    "    pred_missing = best_df['gaps'].tolist()\n",
    "    present_skills = best_df['resume_matched'].tolist()\n",
    "\n",
    "    results[name] = {\n",
    "        \"found\"       : scoring.found_score(true_missing, pred_missing),\n",
    "        \"unnecessary\" : scoring.unnecessary_score(true_missing, pred_missing),\n",
    "        \"redundant\"   : scoring.redundant_score(pred_missing, present_skills),\n",
    "        \"presence\"    : scoring.presence_score(true_missing, pred_missing),\n",
    "        \"n_resumes\"   : len(best_df)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "557a7830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "FINAL SCORES\n",
      "==========================================================================================\n",
      "       found  unnecessary  redundant  presence  n_resumes\n",
      "0.45  0.0342       0.5702        0.0    0.1481    54389.0\n",
      "0.55  0.1525       0.8062        0.0    0.5162    75192.0\n",
      "==========================================================================================\n",
      "BEST THRESHOLD → 0.55\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).T.round(4)\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL SCORES\")\n",
    "print(\"=\"*90)\n",
    "print(results_df[['found', 'unnecessary', 'redundant', 'presence', 'n_resumes']])\n",
    "print(\"=\"*90)\n",
    "print(\"BEST THRESHOLD →\", results_df['found'].idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c10164f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "FINAL SCORES\n",
      "==========================================================================================\n",
      "       found  unnecessary  redundant  presence  n_resumes\n",
      "0.65  0.1773       0.8373        0.0    0.5291     3871.0\n",
      "0.75  0.1486       0.8588        0.0    0.4089     4678.0\n",
      "0.85  0.1774       0.8426        0.0    0.4725     5111.0\n",
      "==========================================================================================\n",
      "BEST THRESHOLD → 0.85\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).T.round(4)\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL SCORES\")\n",
    "print(\"=\"*90)\n",
    "print(results_df[['found', 'unnecessary', 'redundant', 'presence', 'n_resumes']])\n",
    "print(\"=\"*90)\n",
    "print(\"BEST THRESHOLD →\", results_df['found'].idxmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
