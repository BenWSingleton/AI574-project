{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81efe04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scoring\n",
    "from ast import literal_eval\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18bdba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return [str(item).strip() for item in x if str(item).strip()]\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return [str(item).strip() for item in x.flatten() if str(item).strip()]\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            parsed = literal_eval(x)\n",
    "            if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                return [str(item).strip() for item in parsed if str(item).strip()]\n",
    "        except:\n",
    "            pass\n",
    "        return [s.strip() for s in x.replace('[','').replace(']','').split(',') if s.strip()]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd77fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.read_parquet('processed/resume_matched.parquet', columns=['ID', 'matched_skills'])\n",
    "jobs = pd.read_parquet('processed/dice_job_descriptions_matched.parquet', columns=['jobid', 'matched_skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e607d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['matched_skills'] = resumes['matched_skills'].apply(parse)\n",
    "jobs['matched_skills'] = jobs['matched_skills'].apply(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c390ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    \"0.85\": \"matches/ind_skills_scores_085.parquet\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1de6f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating threshold 0.85...\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, path in thresholds.items():\n",
    "    print(f\"\\nEvaluating threshold {name}...\")\n",
    "    \n",
    "    df = pd.read_parquet(path)\n",
    "    df['gaps'] = df['gaps'].apply(parse)\n",
    "    df['has_gap'] = df['gaps'].str.len() > 0\n",
    "\n",
    "    with_gaps = df[df['has_gap']].copy()\n",
    "\n",
    "    if len(with_gaps) == 0:\n",
    "        print(\"  No pairs with gaps found at this threshold!\")\n",
    "        continue\n",
    "    \n",
    "    top10_with_gaps = (with_gaps\n",
    "                       .sort_values(['resume_id', 'pct_job_covered'], ascending=[True, False])\n",
    "                       .groupby('resume_id')\n",
    "                       .head(10))\n",
    "    \n",
    "    top10 = top10_with_gaps.merge(resumes.rename(columns={'ID':'resume_id','matched_skills':'resume_matched'}), \n",
    "                                  on='resume_id', how='left')\n",
    "    top10 = top10.merge(jobs.rename(columns={'jobid':'job_id','matched_skills':'job_matched'}), \n",
    "                        on='job_id', how='left')\n",
    "    \n",
    "    top10['resume_matched'] = top10['resume_matched'].apply(lambda x: x if isinstance(x,list) else [])\n",
    "    top10['job_matched']    = top10['job_matched'].apply(lambda x: x if isinstance(x,list) else [])\n",
    "    \n",
    "    true_missing = [list(set(row.job_matched) - set(row.resume_matched)) for row in top10.itertuples()]\n",
    "    pred_missing = top10['gaps'].tolist()\n",
    "    present_skills = top10['resume_matched'].tolist()\n",
    "    \n",
    "    results[name] = {\n",
    "        \"found\"       : scoring.found_score(true_missing, pred_missing),\n",
    "        \"unnecessary\" : scoring.unnecessary_score(true_missing, pred_missing),\n",
    "        \"redundant\"   : scoring.redundant_score(pred_missing, present_skills),\n",
    "        \"presence\"    : scoring.presence_score(true_missing, pred_missing),\n",
    "        \"median_coverage\": top10['pct_job_covered'].median(),\n",
    "        \"median_gaps\"    : top10['gaps'].str.len().median(),\n",
    "        \"n_pairs\"        : len(top10),\n",
    "        \"n_resumes\"      : top10['resume_id'].nunique(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "557a7830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "FINAL SCORES\n",
      "==========================================================================================\n",
      "       found  unnecessary  redundant  presence  n_resumes\n",
      "0.85  0.0561        0.849        0.0    0.1588      119.0\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).T.round(4)\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL SCORES\")\n",
    "print(\"=\"*90)\n",
    "print(results_df[['found', 'unnecessary', 'redundant', 'presence', 'n_resumes']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
